# Customer Churn Prediction using Machine Learning

![Customer Churn](images/customer_churn.png)

## ðŸ“– Overview

This project predicts customer churn (whether a customer will leave or stay) for an e-commerce platform using machine learning techniques. Early identification of potential churners allows businesses to take proactive measures to retain customers.

We use customer data to analyze patterns and build predictive models, including:

* Logistic Regression
* Support Vector Machines (SVM)
* Decision Tree
* Random Forest
* XGBoost

---

## ðŸ“Š Dataset

The dataset contains **5630 customers** with **20 columns** describing their behavior and demographics.
Key column: `Churn` â€“ indicates whether a customer has left (1) or stayed (0).

### Sample data:

| CustomerID | Gender | MaritalStatus | Tenure | OrderCount | CashbackAmount | Complain | Churn |
| ---------- | ------ | ------------- | ------ | ---------- | -------------- | -------- | ----- |
| 1          | Male   | Married       | 12     | 5          | 10             | No       | 0     |
| 2          | Female | Single        | 3      | 1          | 0              | Yes      | 1     |

### Churn distribution:

![Churn Pie Chart](images/churn_pie.png)

> 4682 customers stayed, 948 customers left (~17% churn rate)

---

## ðŸ”Ž Exploratory Data Analysis (EDA)

* **Numerical features:** Tenure, OrderCount, CashbackAmount
* **Categorical features:** Gender, MaritalStatus, Complain

### Examples:

#### Tenure Distribution

![Tenure Histogram](images/tenure_hist.png)

#### Gender vs Churn

![Gender vs Churn](images/gender_churn.png)

---

## ðŸ”§ Data Preprocessing

1. Handle missing values (dropped rows with NaN)
2. Encode categorical variables using `pd.get_dummies()`
3. Standardize features using `StandardScaler()`
4. Split data into training and test sets (`train_test_split`)

---

## ðŸ¤– Machine Learning Models

### Logistic Regression

* Accuracy: 0.90
* ROC Curve:
  ![ROC LR](images/roc_lr.png)

### Support Vector Machine

* Accuracy: 0.88
* ROC Curve:
  ![ROC SVM](images/roc_svm.png)

### Decision Tree

* Accuracy: 0.85
* Feature importance visualized:
  ![Decision Tree](images/decision_tree.png)

### Random Forest

* Accuracy: 0.91
* Confusion Matrix:
  ![Confusion Matrix RF](images/confusion_matrix_rf.png)

### XGBoost

* Accuracy: 0.92
* Confusion Matrix:
  ![Confusion Matrix XGB](images/confusion_matrix_xgb.png)

---

## ðŸ“š Insights

* Customers with **short tenure** and **recent complaints** are more likely to churn.
* **Cashback usage** and **order frequency** are important features for predicting churn.
* Ensemble models (Random Forest, XGBoost) provide the highest accuracy.

---

## âš¡ Installation & Usage

```bash
git clone https://github.com/YourUsername/Customer-Churn-Prediction-ML.git
cd Customer-Churn-Prediction-ML
pip install -r requirements.txt
jupyter notebook 05-ML-14-Customer-churn.ipynb
```

---

## ðŸ“‚ Repository Structure

```
Customer-Churn-Prediction-ML/
â”‚
â”œâ”€â”€ 05-ML-14-Customer-churn.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ E-Commerce-Dataset.xlsx
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ customer_churn.png
â”‚   â”œâ”€â”€ churn_pie.png
â”‚   â”œâ”€â”€ tenure_hist.png
â”‚   â”œâ”€â”€ gender_churn.png
â”‚   â”œâ”€â”€ roc_lr.png
â”‚   â”œâ”€â”€ roc_svm.png
â”‚   â”œâ”€â”€ decision_tree.png
â”‚   â”œâ”€â”€ confusion_matrix_rf.png
â”‚   â””â”€â”€ confusion_matrix_xgb.png
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ðŸ”— References

* [Scikit-learn Documentation](https://scikit-learn.org/stable/)
* [XGBoost Documentation](https://xgboost.readthedocs.io/)
* E-Commerce Dataset: [GitHub link](https://github.com/anvarnarz/praktikum_datasets)

---

## ðŸ‘¤ Author

**Behruz Maxmudov**

* Email: [behruzmaxmudov263@gmail.com](mailto:behruzmaxmudov263@gmail.com)
* GitHub: [https://github.com/BehruzMaxmudov1203](https://github.com/BehruzMaxmudov1203)

---

## ðŸ”§ Requirements

```
pandas
numpy
matplotlib
seaborn
scikit-learn
xgboost
openpyxl
jupyter
```
